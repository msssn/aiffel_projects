{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aquatic-bradford",
   "metadata": {},
   "source": [
    "# Image classification (Rock, Scissor, Paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-genesis",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n",
    "전에 Exploration_1에서 실습했던 숫자 손글씨는 이미지 크기가 28x28이었기 때문에,\n",
    "설계된 모델에 맞추려면 가위바위보 이미지도 28x28로 만들어줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "successful-kidney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리 블러오기\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-parent",
   "metadata": {},
   "source": [
    "### 1-1. 가위바위보 이미지 크기 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "structural-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 변환 함수\n",
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "understood-explosion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 모든 가위 이미지 변환 (train dataset 사용)\n",
    "\n",
    "# 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서 변환\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "monthly-shock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 모든 바위 이미지 변환 (train dataset 사용)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "western-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 모든 보 이미지 변환 (train dataset 사용)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-configuration",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-outside",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리\n",
    "### 2-1. 불러오기\n",
    "숫자 손글씨 인식기에서는 mnist.load_data()라는 함수로 데이터를 불러왔음.\n",
    "여기서는 load_data() 함수를 만들어서 데이터를 불러오도록 하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adapted-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "(300, 28, 28, 3)\n",
      "(300,)\n",
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "# load_data() 함수\n",
    "# 입력으로 이미지가 있는 폴더 위치를 받는다\n",
    "# 숫자 손글씨 인식기와는 다르게 10개의 클래스 (0~9)가 아닌 3개의 클래스 (가위:0, 바위:1, 보:2)이다.\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "\n",
    "# 데이터 파악하기\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "# **** 숫자 손글씨 이미지와 같이 0~255의 픽셀 값을 가진다?? ****\n",
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "designed-story",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n",
      "최소값: 0.0  최대값: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print('최소값:',np.min(x_train_norm), ' 최대값:',np.max(x_train_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "municipal-antibody",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지를 한번 불러와 보자\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-tournament",
   "metadata": {},
   "source": [
    "## 3. 딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "floral-breeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "# 처음은 숫자 손글씨 이미지 때와 비슷하게 간다. **** 마지막 Dense만 3으로 바꿈 ****\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 결과적으로 분류해 내야 하는 클래스: 3개!\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "#딥러닝 네트워크 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-bacon",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-murray",
   "metadata": {},
   "source": [
    "## 4. 딥러닝 네트워크 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "circular-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 5s 191ms/step - loss: 1.1047 - accuracy: 0.3697\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0509 - accuracy: 0.4206\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9797 - accuracy: 0.6125\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9137 - accuracy: 0.5932\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8527 - accuracy: 0.6369\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7031 - accuracy: 0.8381\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.7782\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.8705\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.8933\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.9465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7d43564750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-smoke",
   "metadata": {},
   "source": [
    "## 5. 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-monroe",
   "metadata": {},
   "source": [
    "### 5-1. 테스트용 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fewer-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1797 입니다.\n",
      "(1797, 28, 28, 3)\n",
      "(1797,)\n",
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "def load_data_test(img_path, number_of_data=1797):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs_test=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels_test=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/scissors_complete/*.jpg'):\n",
    "        img_test = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs_test[idx,:,:,:]=img_test    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels_test[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/rocks_complete/*.jpg'):\n",
    "        img_test = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs_test[idx,:,:,:]=img_test    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels_test[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/papers_complete/*.jpg'):\n",
    "        img_test = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs_test[idx,:,:,:]=img_test    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels_test[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs_test, labels_test\n",
    "\n",
    "image_dir_path_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data_test(image_dir_path_test)\n",
    "\n",
    "# 데이터 파악하기\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "# **** 숫자 손글씨 이미지와 같이 0~255의 픽셀 값을 가진다?? ****\n",
    "print('최소값:',np.min(x_test), ' 최대값:',np.max(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fifteen-centre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1797, 28, 28, 3)\n",
      "y_train shape: (1797,)\n",
      "최소값: 0.0  최대값: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_test.shape))\n",
    "print(\"y_train shape: {}\".format(y_test.shape))\n",
    "print('최소값:',np.min(x_test_norm), ' 최대값:',np.max(x_test_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thirty-plaza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지를 한번 불러와 보자\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[0])\n",
    "print('라벨: ', y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-smell",
   "metadata": {},
   "source": [
    "### 5-2. 테스트용 데이터로 성능 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pleased-package",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 - 1s - loss: 1.3006 - accuracy: 0.3072\n",
      "test_loss: 1.3006423711776733 \n",
      "test_accuracy: 0.3071786165237427\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-butterfly",
   "metadata": {},
   "source": [
    "## 6. 더 좋은 네트워크 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-delaware",
   "metadata": {},
   "source": [
    "### 6-1. 하이퍼 파라미터 바꾸기\n",
    "1. Conv2D layer (입력 이미지의 특징 수) 바꾸기\n",
    "2. Dense layer (뉴런 수) 바꾸기\n",
    "3. epoch (학습 반복 횟수) 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "frequent-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 485,763\n",
      "Trainable params: 485,763\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 4s 214ms/step - loss: 1.1282 - accuracy: 0.3461\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0477 - accuracy: 0.5029\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8593 - accuracy: 0.7831\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.7482\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.8635\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2630 - accuracy: 0.9356\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1401 - accuracy: 0.9872\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9953\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0186 - accuracy: 0.9956\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.8653e-04 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.5044e-04 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.4012e-04 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.0576e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6632e-04 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4822e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3968e-04 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.7363e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.3040e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2236e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2182e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6990e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9510e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9015e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.8008e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5036e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3001e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0025e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8274e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9147e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.5306e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.6066e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.4022e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3880e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2412e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1781e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0926e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0787e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0488e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.4639e-05 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.3793e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.6943e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.5426e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1302e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.6518e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.5822e-05 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.8004e-05 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.9930e-05 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5800e-05 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7271e-05 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.2663e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 4.7295e-05 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.3737e-05 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.1600e-05 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4.2224e-05 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.8240e-05 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.9297e-05 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.7300e-05 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.6429e-05 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.3378e-05 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.4776e-05 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.0184e-05 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.9040e-05 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3.1990e-05 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.6887e-05 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5298e-05 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5351e-05 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.5362e-05 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3328e-05 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.1994e-05 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3172e-05 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.4443e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.3217e-05 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0441e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0223e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6940e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8518e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7065e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9666e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.6856e-05 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7167e-05 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8666e-05 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5411e-05 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5679e-05 - accuracy: 1.0000\n",
      "57/57 - 1s - loss: 4.1286 - accuracy: 0.4574\n",
      "test_loss: 4.128592014312744 \n",
      "test_accuracy: 0.45742905139923096\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=64\n",
    "n_channel_2=128\n",
    "n_dense=128\n",
    "n_train_epoch=100\n",
    "\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 결과적으로 분류해 내야 하는 클래스: 3개!\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "# 딥러닝 네트워크 확인\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch) \n",
    "\n",
    "# 5. 테스트\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-conspiracy",
   "metadata": {},
   "source": [
    "### 6-2. train과 test data 바꿔보기\n",
    " - train dataset이 너무 작음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "light-fleet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 485,763\n",
      "Trainable params: 485,763\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 2s 26ms/step - loss: 1.0419 - accuracy: 0.4378\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6116 - accuracy: 0.7689\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8733\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9333\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9772\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.8809\n",
      "Epoch 7/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9931\n",
      "Epoch 8/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9869\n",
      "Epoch 9/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9983\n",
      "Epoch 10/100\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9974\n",
      "Epoch 11/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9987\n",
      "Epoch 12/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9999\n",
      "Epoch 13/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9988\n",
      "Epoch 14/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 9.4742e-04 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 7.8450e-04 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 6.7392e-04 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 6.6975e-04 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.5518e-04 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.2826e-04 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.8468e-04 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.9539e-04 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.5457e-04 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.6438e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.7431e-04 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.2539e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.2256e-04 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.7473e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.2672e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.0956e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.3480e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.9845e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.7020e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.9452e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.6925e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.9062e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.2567e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.3619e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2376e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1842e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1550e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 9.1351e-05 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.0094e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2400e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 9.0284e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 8.0878e-05 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 8.1443e-05 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 7.4950e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.9599e-05 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 6.6814e-05 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 6.9105e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.7721e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.7522e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.3505e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.3341e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.3399e-05 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.2569e-05 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.5174e-05 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.2312e-05 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.7032e-05 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.2144e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 4ms/step - loss: 3.8248e-05 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.6456e-05 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.4584e-05 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.6564e-05 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.8789e-05 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.0450e-05 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.5640e-05 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.8736e-05 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.6299e-05 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.6523e-05 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.8724e-05 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.1461e-05 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.3545e-05 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.3752e-05 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.3840e-05 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.2212e-05 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.0928e-05 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.6416e-05 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.8296e-05 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.6572e-05 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.7411e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.3952e-05 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.4142e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.6058e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2498e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1675e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.3496e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1125e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.1043e-05 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.1046e-05 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 9.6049e-06 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 9.5736e-06 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.0660e-05 - accuracy: 1.0000\n",
      "10/10 - 0s - loss: 9.5742 - accuracy: 0.5033\n",
      "test_loss: 9.574237823486328 \n",
      "test_accuracy: 0.503333330154419\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=64\n",
    "n_channel_2=128\n",
    "n_dense=128\n",
    "n_train_epoch=100\n",
    "\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 결과적으로 분류해 내야 하는 클래스: 3개!\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "# 딥러닝 네트워크 확인\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_test_norm, y_test, epochs=n_train_epoch) \n",
    "\n",
    "# 5. 테스트\n",
    "test_loss, test_accuracy = model.evaluate(x_train_norm, y_train, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-carry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
